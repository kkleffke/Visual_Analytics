{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372f21f4",
   "metadata": {},
   "source": [
    "## Visual Analytics \n",
    "### Small web scraping for the final Project \n",
    "##### Supervisors:  Sippo Rossi & Ivanna Jurkiv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86aced2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6d12d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         summit_name  krankenh.gif  gipfelm.gif  gipfeln.gif  quacke.gif  \\\n",
      "0           Hallodri           2.0          0.0          0.0         0.0   \n",
      "1        Lehnwächter           1.0          0.0          1.0         0.0   \n",
      "2         Lorenzwand           3.0          1.0          0.0         0.0   \n",
      "3        Lorenznadel           2.0          0.0          1.0         0.0   \n",
      "4          Domkanzel           1.0          0.0          0.0         0.0   \n",
      "..               ...           ...          ...          ...         ...   \n",
      "884  Hausbergwächter           0.0          0.0          1.0         0.0   \n",
      "885   Großsteinnadel           0.0          0.0          1.0         0.0   \n",
      "886  Teichsteinnadel           0.0          0.0          1.0         0.0   \n",
      "887    E-Flügel-Wand           0.0          0.0          1.0         0.0   \n",
      "888       Buschmühle           0.0          0.0          0.0         0.0   \n",
      "\n",
      "     gipfelgr.gif  kreuz.gif  muell.gif  \n",
      "0             0.0        0.0        NaN  \n",
      "1             0.0        0.0        NaN  \n",
      "2             0.0        0.0        NaN  \n",
      "3             0.0        0.0        NaN  \n",
      "4             0.0        0.0        NaN  \n",
      "..            ...        ...        ...  \n",
      "884           0.0        0.0        0.0  \n",
      "885           0.0        0.0        0.0  \n",
      "886           0.0        0.0        0.0  \n",
      "887           0.0        0.0        0.0  \n",
      "888           1.0        0.0        0.0  \n",
      "\n",
      "[889 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating link to scrape\n",
    "link = \"http://db-sandsteinklettern.gipfelbuch.de/gipfel.php?sektorid=\"\n",
    "\n",
    "#defining the range of pages IDs to scrape\n",
    "numbers = list(range(123,136))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#looping through the pages\n",
    "for number in numbers:\n",
    "    new_link = link + str(number) #add number to link\n",
    "    ht = requests.get(new_link) #GET request\n",
    "    soup = BeautifulSoup(ht.text) #paring trough htlm document\n",
    "    table = soup.find(\"table\") #looking for the table in the htlm\n",
    "\n",
    "    rows=list() \n",
    "    for row in table.findAll(\"tr\"): #iterating over rows in table\n",
    "        rows.append(row) #appending them\n",
    "    imgs = {}\n",
    "\n",
    "    for row in rows: #iterating over appended rows\n",
    "        string =str(row)\n",
    "        string = string.replace('\"',\"\")\n",
    "        match = re.search(r'<font size=>(\\d{2,3}G[A-Z]?)</font>', string) #search for this part in the html\n",
    "        if match:\n",
    "            extracted_part = match.group(1) #if match, extract this part\n",
    "\n",
    "    for row in rows[2:]:\n",
    "        s = str(row)\n",
    "        gid = row.find_all('a')[0].text #getting the name of summit\n",
    "        imgs[gid] = Counter([x.get(\"src\") for x in row.find_all(\"img\")]) #getting count of gifs\n",
    "\n",
    "    new_df = pd.DataFrame.from_dict(imgs, orient='index') #create DataFrame from dictionary\n",
    "    new_df = new_df.reset_index() \n",
    "    new_df = new_df.rename(columns={'index':'summit_name'}) #rename columns\n",
    "    new_df = new_df.fillna(0) #fill missing values with 0\n",
    "    df = pd.concat([df, new_df], ignore_index=True) #concatenate dataframes\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2ddc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning summit_name\n",
    "#strip trailing characters\n",
    "df[\"summit_name\"] = df[\"summit_name\"].str.rstrip(\" /.\")\n",
    "\n",
    "#split and select first element\n",
    "df[\"summit_name\"] = df[\"summit_name\"].str.split(\"/\").str[0]\n",
    "\n",
    "#strip trailing spaces\n",
    "df[\"summit_name\"] = df[\"summit_name\"].str.rstrip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c95caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only specified columns\n",
    "df = df[[\"summit_name\",\"kreuz.gif\",\"krankenh.gif\"]]\n",
    "\n",
    "#rename columns\n",
    "df.rename(columns={'kreuz.gif': 'deaths_on_summit', 'krankenh.gif': 'accidents'}, inplace=True)\n",
    "\n",
    "#save to csv file\n",
    "df.to_csv(\"gif_count.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
