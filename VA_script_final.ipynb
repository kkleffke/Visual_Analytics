{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a44f15",
   "metadata": {},
   "source": [
    "## Visual Analytics \n",
    "### Data cleaning for the final Project \n",
    "##### Supervisors:  Sippo Rossi & Ivanna Jurkiv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2945eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing important librarys\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from googletrans import Translator, constants\n",
    "\n",
    "#Adding the progress bar capability to pandas using tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28db5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "dfs = pd.read_excel('v0.1__data_climbing.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb37429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the sheets as a DataFrame\n",
    "df_sub_region = dfs['Teilgebiet']\n",
    "df_summit = dfs['Gipfel']\n",
    "df_routes = dfs['Wege']\n",
    "df_comments = dfs['Kommentare']\n",
    "df_scales = dfs[\"scales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da861df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sector_id             sectorname  stars\n",
      "0         134                 Wehlen      3\n",
      "1         130                 Rathen      5\n",
      "2         128                  Brand      0\n",
      "3         132          Schrammsteine      5\n",
      "4         131               Schmilka      5\n",
      "5         123            Affensteine      0\n",
      "6         129        Kleiner Zschand      0\n",
      "7         126         Großer Zschand      0\n",
      "8         135   Wildensteiner Gebiet      0\n",
      "9         127        Hinterhermsdorf      3\n",
      "10        133      Gebiet der Steine      5\n",
      "11        124               Bielatal      4\n",
      "12        125  Erzgebirgsgrenzgebiet      0\n"
     ]
    }
   ],
   "source": [
    "#renaming columns in dataframe\n",
    "df_sub_region = df_sub_region.rename(columns = {\"Sterne \":\"stars\",\n",
    "                                                \"SEKTORID\":\"sector_id\",\n",
    "                                                \"SEKTORNAME_D\":\"sectorname\"})\n",
    "df_sub_region = df_sub_region.iloc[:, :-2] #remove last 2 columns\n",
    "print(df_sub_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f116d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  summit_id  summit_name  summit_type        gps_lat  \\\n",
      "0        123     3437.0     Vagabund          NaN     50,9093088   \n",
      "1        123     3438.0     Hallodri          NaN     50,9092927   \n",
      "2        123     3439.0     Lehnhorn          2.0     50,9089816   \n",
      "3        123     3440.0  Lehnwächter          3.0     50,9083915   \n",
      "4        123     3441.0  Lorenzsporn          4.0  50,9094722222   \n",
      "\n",
      "        gps_long  POSFEHLER  count_routes  summit_counts  \n",
      "0     14,2197579       10.0           NaN            119  \n",
      "1     14,2199028       10.0           NaN            119  \n",
      "2     14,2203265       10.0           NaN            119  \n",
      "3  14,2227222222       40.0           NaN            119  \n",
      "4  14,2236111111       40.0           NaN            119  \n"
     ]
    }
   ],
   "source": [
    "#renaming columns\n",
    "df_summit = df_summit.rename(columns = {\"SEKTORID\":\"sector_id\",\n",
    "                                        \"GIPFELID\":\"summit_id\",\n",
    "                                        \"GIPFELNAME_D\":\"summit_name\",\n",
    "                                        \"LAT\":\"gps_lat\",\n",
    "                                        \"LONG\":\"gps_long\",\n",
    "                                        \"Anzahl Wege\": \"count_routes\",\n",
    "                                        \"GIPFELWERTUNG\":\"summit_type\"})\n",
    "\n",
    "\n",
    "df_summit = df_summit.iloc[:, :-3].dropna(how = \"all\") #remove last 3 columns and row if all \"NaN\"\n",
    "\n",
    "#fixing messed up gps numbers (change to str for the next step)\n",
    "df_summit[\"gps_lat\"] = df_summit[\"gps_lat\"].astype(str)\n",
    "df_summit[\"gps_long\"] = df_summit[\"gps_long\"].astype(str)\n",
    "\n",
    "#implementing a dot at the right position\n",
    "df_summit[\"gps_lat\"] = df_summit[\"gps_lat\"].str.replace('.', '',regex=False).str[:2] + \",\" + df_summit[\"gps_lat\"].str[2:-2].fillna(0)\n",
    "df_summit[\"gps_long\"] = df_summit[\"gps_long\"].str.replace('.', '',regex=False).str[:2] + \",\" + df_summit[\"gps_long\"].str[2:-2].fillna(0)\n",
    "\n",
    "#gettig all summits for each sector \n",
    "df_summit[\"summit_counts\"] = df_summit.groupby(\"sector_id\")[\"sector_id\"].transform(\"count\")\n",
    "df_summit[\"sector_id\"] = df_summit[\"sector_id\"].fillna(0)\n",
    "df_summit[\"sector_id\"] = df_summit[\"sector_id\"].astype(int)\n",
    "\n",
    "df_summit.loc[df_summit[\"summit_type\"] > 5, \"summit_type\"] = np.nan  #cleaning the column\n",
    "\n",
    "#merging on \"sector_id\" and dropping duplicates\n",
    "df_sub_region = df_sub_region.merge(df_summit[[\"sector_id\",\"summit_counts\"]], on = \"sector_id\", how = \"left\").drop_duplicates()\n",
    "\n",
    "print(df_summit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9d4552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector_id          int32\n",
      "summit_id        float64\n",
      "summit_name       object\n",
      "summit_type      float64\n",
      "gps_lat           object\n",
      "gps_long          object\n",
      "POSFEHLER        float64\n",
      "count_routes     float64\n",
      "summit_counts      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_summit.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f921458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           summit_id  summit_name  summit_type  gps_lat  gps_long  POSFEHLER  \\\n",
      "sector_id                                                                      \n",
      "123              119          119           79      119       119        119   \n",
      "124              249          249          122      249       249        249   \n",
      "125               16           16           14       16        16         16   \n",
      "126               86           86           60       86        86         86   \n",
      "127               17           17           17       17        17         17   \n",
      "128               84           84           51       84        84         84   \n",
      "129               44           44           32       44        44         44   \n",
      "130              148          148          103      148       148        148   \n",
      "131              127          127           68      127       127        127   \n",
      "132               81           81           63       81        81         81   \n",
      "133              112          112          104      112       112        112   \n",
      "134               18           18           16       18        18         18   \n",
      "135               42           42           31       42        42         42   \n",
      "\n",
      "           count_routes  summit_counts  \n",
      "sector_id                               \n",
      "123                   0            119  \n",
      "124                   0            249  \n",
      "125                   0             16  \n",
      "126                   0             86  \n",
      "127                   0             17  \n",
      "128                   0             84  \n",
      "129                   0             44  \n",
      "130                   0            148  \n",
      "131                   0            127  \n",
      "132                   0             81  \n",
      "133                   0            112  \n",
      "134                   0             18  \n",
      "135                   0             42  \n"
     ]
    }
   ],
   "source": [
    "print(df_summit.groupby(\"sector_id\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c26fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   summit_id  route_id            route_name                    first_ascent  \\\n",
      "0       3437      1382             Alter Weg                  Wolfgang Poock   \n",
      "1       3437     18682       Variante zum AW                    Günter Schär   \n",
      "2       3437     92855               Westweg                   Manfred Vogel   \n",
      "3       3437     65288           Pennermatte                   Volkmar Werth   \n",
      "4       3437     18683  Südwestverschneidung  Jürgen Weber und Günter Müller   \n",
      "\n",
      "      fa_group              fa_date  \\\n",
      "0         vug.  1959-11-01 00:00:00   \n",
      "1  S. Hoffmann  1960-07-24 00:00:00   \n",
      "2          vug  2017-05-10 00:00:00   \n",
      "3    F. Bonitz  1994-07-07 00:00:00   \n",
      "4          NaN  1960-08-07 00:00:00   \n",
      "\n",
      "                                route_description_de tags grade  quality  \\\n",
      "0  Vom Massiv absteigen und durch Kamin zur O-Kan...  NaN    IV      0.0   \n",
      "1  Links in der N-Wand Kamin in Winkel einige m h...  NaN    IV      0.0   \n",
      "2                                                NaN  NaN  VIIa      0.0   \n",
      "3  4 m rechts der \"Südwestverschneidung\" teils üb...  NaN   IXa      0.0   \n",
      "4  In Mitte SW-Wand zu Riss und Verschneidung zum...  NaN    VI      0.0   \n",
      "\n",
      "   safety  wet  safety_rings  status_route  routes_per_summit  \n",
      "0     0.0  0.0           0.0             1                 12  \n",
      "1     0.0  NaN           0.0             1                 12  \n",
      "2     0.0  NaN           1.0             1                 12  \n",
      "3     0.0  NaN           2.0             1                 12  \n",
      "4     0.0  NaN           0.0             1                 12  \n"
     ]
    }
   ],
   "source": [
    "#renaming columns\n",
    "df_routes = df_routes.rename(columns = {\"GIPFELID\":\"summit_id\",\n",
    "                                        \"WEGID\":\"route_id\",\n",
    "                                        \"WEGNAME_D\":\"route_name\",\n",
    "                                        \"ERSTBEGEHERVORSTIEG\":\"first_ascent\",\n",
    "                                        \"ERSTBEGEHERNACHSTIEG\":\"fa_group\",\n",
    "                                        \"ERSTBEGEHUNGSDATUM\":\"fa_date\",\n",
    "                                        \"WEGBESCHREIBUNG_D\":\"route_description_de\",\n",
    "                                        \"STICHWORTE\":\"tags\",\n",
    "                                        \"SCHWIERIGKEIT\":\"grade\",\n",
    "                                        \"QUALITAET\":\"quality\",\n",
    "                                        \"SICHERUNG\":\"safety\",\n",
    "                                        \"NAESSE\":\"wet\",\n",
    "                                        \"RINGZAHL\":\"safety_rings\",\n",
    "                                        \"WEGSTATUS\":\"status_route\"\n",
    "                                       })\n",
    "df_routes = df_routes.iloc[:, :-1] #remove last column\n",
    "\n",
    "#remove routes where we don't have the summit for\n",
    "df_routes = df_routes[df_routes['summit_id'].isin(df_summit['summit_id'])]\n",
    "\n",
    "#count the routes_per_summit\n",
    "df_routes[\"routes_per_summit\"] = df_routes.groupby(\"summit_id\")[\"summit_id\"].transform(\"count\")\n",
    "\n",
    "print(df_routes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd66d580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   summit_id  route_id            route_name                    first_ascent  \\\n",
      "0       3437      1382             Alter Weg                  Wolfgang Poock   \n",
      "1       3437     18682       Variante zum AW                    Günter Schär   \n",
      "2       3437     92855               Westweg                   Manfred Vogel   \n",
      "3       3437     65288           Pennermatte                   Volkmar Werth   \n",
      "4       3437     18683  Südwestverschneidung  Jürgen Weber und Günter Müller   \n",
      "\n",
      "      fa_group     fa_date                               route_description_de  \\\n",
      "0         vug.  1959-11-01  Vom Massiv absteigen und durch Kamin zur O-Kan...   \n",
      "1  S. Hoffmann  1960-07-24  Links in der N-Wand Kamin in Winkel einige m h...   \n",
      "2          vug  2017-05-10                                                NaN   \n",
      "3    F. Bonitz  1994-07-07  4 m rechts der \"Südwestverschneidung\" teils üb...   \n",
      "4          NaN  1960-08-07  In Mitte SW-Wand zu Riss und Verschneidung zum...   \n",
      "\n",
      "  tags grade  quality  safety  wet  safety_rings  status_route  \\\n",
      "0  NaN    IV      0.0     0.0  0.0           0.0             1   \n",
      "1  NaN    IV      0.0     0.0  NaN           0.0             1   \n",
      "2  NaN  VIIa      0.0     0.0  NaN           1.0             1   \n",
      "3  NaN   IXa      0.0     0.0  NaN           2.0             1   \n",
      "4  NaN    VI      0.0     0.0  NaN           0.0             1   \n",
      "\n",
      "   routes_per_summit  beautiful  \n",
      "0                 12        0.0  \n",
      "1                 12        0.0  \n",
      "2                 12        0.0  \n",
      "3                 12        0.0  \n",
      "4                 12        0.0  \n"
     ]
    }
   ],
   "source": [
    "#get only routes which we have a summit for\n",
    "df_routes = df_routes[df_routes['summit_id'].isin(df_summit['summit_id'])]\n",
    "\n",
    "#star at the beginning of the name indicates beautiful route\n",
    "df_routes[\"beautiful\"] = df_routes[\"route_name\"].str.count(\"^\\*\")\n",
    "df_routes[\"route_name\"] = df_routes[\"route_name\"].str.replace(\"^\\*\", \"\",regex=True)\n",
    "\n",
    "#transforming fa_date elements\n",
    "df_routes[\"fa_date\"] = df_routes[\"fa_date\"].astype(str)\n",
    "df_routes[\"fa_date\"] = df_routes[\"fa_date\"].replace(\"0000-00-00\", \"0\")\n",
    "df_routes[\"fa_date\"] = df_routes[\"fa_date\"].apply(lambda x: x[:-9] if x.endswith(\" 00:00:00\") else x)\n",
    "print(df_routes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183d7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting routes_counts summed by summit_id \n",
    "\n",
    "#creating new dataframes 's_df' and 'b_df'\n",
    "s_df = df_routes[[\"summit_id\",\"route_id\",\"routes_per_summit\"]]\n",
    "b_df = df_summit[[\"summit_id\",\"sector_id\",\"summit_counts\"]]\n",
    "b_df[\"summit_id\"] = b_df[\"summit_id\"].astype(int)\n",
    "\n",
    "# Merging on 'summit_id' column to create 'm_db'\n",
    "m_db = b_df.merge(s_df, left_on = \"summit_id\", right_on = \"summit_id\")\n",
    "\n",
    "#calculating 'routes_counts_per_sec' for each sector\n",
    "m_db[\"routes_counts_per_sec\"] = m_db.groupby(\"sector_id\")[\"sector_id\"].transform(\"count\")\n",
    "\n",
    "#merging on 'sector_id' column, and dropping duplicates\n",
    "df_sub_region = df_sub_region.merge(m_db[[\"sector_id\",\"routes_counts_per_sec\"]], on = \"sector_id\", how = \"left\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1098600c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sector_id             sectorname  stars  summit_counts  \\\n",
      "0            134                 Wehlen      3             18   \n",
      "289          130                 Rathen      5            148   \n",
      "2986         128                  Brand      0             84   \n",
      "4819         132          Schrammsteine      5             81   \n",
      "6509         131               Schmilka      5            127   \n",
      "8900         123            Affensteine      0            119   \n",
      "11060        129        Kleiner Zschand      0             44   \n",
      "12223        126         Großer Zschand      0             86   \n",
      "13873        135   Wildensteiner Gebiet      0             42   \n",
      "15324        127        Hinterhermsdorf      3             17   \n",
      "15527        133      Gebiet der Steine      5            112   \n",
      "18367        124               Bielatal      4            249   \n",
      "22634        125  Erzgebirgsgrenzgebiet      0             16   \n",
      "\n",
      "       routes_counts_per_sec_x  routes_counts_per_sec_y  routes_counts_per_sec  \n",
      "0                          289                      289                    289  \n",
      "289                       2697                     2697                   2697  \n",
      "2986                      1833                     1833                   1833  \n",
      "4819                      1690                     1690                   1690  \n",
      "6509                      2391                     2391                   2391  \n",
      "8900                      2160                     2160                   2160  \n",
      "11060                     1163                     1163                   1163  \n",
      "12223                     1650                     1650                   1650  \n",
      "13873                     1451                     1451                   1451  \n",
      "15324                      203                      203                    203  \n",
      "15527                     2840                     2840                   2840  \n",
      "18367                     4267                     4267                   4267  \n",
      "22634                      264                      264                    264  \n"
     ]
    }
   ],
   "source": [
    "print(df_sub_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a90d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting display rows, to see how the grades are formated\n",
    "pd.set_option('display.max_rows', 5000000)\n",
    "#fix the grades\n",
    "sgrade_list = df_scales[\"SÄCHSISCH\"].tolist()\n",
    "df_routes['grade'] = df_routes['grade'].astype(str).apply(lambda x: x.split(\" \")[0] if x.split(\" \")[0] in sgrade_list else x)\n",
    "\n",
    "#simplifying/fixing the formating of the grade\n",
    "for i, row in df_routes.iterrows():\n",
    "    if i not in sgrade_list:\n",
    "        if '/' in row['grade']:\n",
    "            #split string and check if second part is in short_list\n",
    "            split_str = row['grade'].split('/')\n",
    "            if split_str[1] in sgrade_list or split_str[1].split(\" \")[0] in sgrade_list:\n",
    "                #replace element with short version\n",
    "                df_routes.at[i, 'grade'] = split_str[1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "473a3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to replace the values in a column\n",
    "def replace_all(col, dic):\n",
    "    for i, j in dic.items():\n",
    "        col = col.replace(i, j)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45ba5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values in 'grade' column\n",
    "dic = {\"1\":\"I\",\"3\":\"III\",\"4\":\"IV\",\"2\":\"II\",\"5\":\"V\",\"6\":\"IV\",\"7\":\"IIV\"}\n",
    "df_routes[\"grade\"] = replace_all(df_routes[\"grade\"],dic)\n",
    "\n",
    "#keep values in 'grade' column in 'sgrade_list'\n",
    "df_routes['grade'] = df_routes['grade'].apply(lambda x: x if x in sgrade_list else \"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc5b6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xc         89\n",
      "Xb        189\n",
      "Xa        369\n",
      "XIc        10\n",
      "XIb        17\n",
      "XIa        32\n",
      "XIIc        9\n",
      "XIIb       32\n",
      "XIIa       48\n",
      "VIIc     2182\n",
      "VIIb     2197\n",
      "VIIa     2193\n",
      "VIIIc    1122\n",
      "VIIIb    1368\n",
      "VIIIa    1527\n",
      "VI       1911\n",
      "V        2164\n",
      "NaN       187\n",
      "IXc       518\n",
      "IXb       724\n",
      "IXa       839\n",
      "IV       2027\n",
      "III      1739\n",
      "II       1036\n",
      "I         369\n",
      "Name: grade, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking the transfomation \n",
    "print(df_routes[\"grade\"].value_counts().sort_index(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6317f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UIAA FRZ. SÄCHSISCH BRITISH (TECH) BRITISH (ADJ) USA (SIERRA) NORDIC (FIN)  \\\n",
      "0    1    1         I              1             M            5            1   \n",
      "1    2    2        II              2           M/D          5.1            2   \n",
      "2    3    3       III              3             D          5.2          2/3   \n",
      "3    4    4        IV             4a          D/VD          5.3            3   \n",
      "4   4+   4+      IV/V             4a            VD          5.4            4   \n",
      "\n",
      "  NORDIC (SWE/NOR) FB-SKALA (BOULDERN) V-SCALE (BOULDERN)  \n",
      "0                1                   1                VB-  \n",
      "1                2                   1                VB-  \n",
      "2              2/3                 1/2                VB-  \n",
      "3                3                   2                VB-  \n",
      "4                4                   2                VB-  \n"
     ]
    }
   ],
   "source": [
    "print(df_scales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a1e8fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  summit_id  route_id  comment_id  \\\n",
      "0        123       3437      1381       28277   \n",
      "1        123       3438      1383       28278   \n",
      "2        123       3439      1389       28498   \n",
      "3        123       3439      1390       28281   \n",
      "4        123       3441      1399       39174   \n",
      "\n",
      "                                          comment_de        date_comment  \\\n",
      "0  Ein echtes Kleinod, das mensch sich allerdings... 2017-06-12 21:31:00   \n",
      "1  Der Einstieg bis zum Ring ist extrem unangeneh... 2017-06-12 21:34:53   \n",
      "2  Immer noch ein hübscher Weg, allerdings sollte... 2017-07-03 14:27:56   \n",
      "3  Eine tolle Linie mit Anspruch. Zum ersten Ring... 2017-06-12 21:41:58   \n",
      "4  Den Aufstieg auf den Pfeiler lieber von links ... 2021-05-25 22:23:23   \n",
      "\n",
      "   quality  safety  grade_maybelater  wet  \n",
      "0      1.0     2.0               6.0  NaN  \n",
      "1      2.0     3.0               9.0  4.0  \n",
      "2      2.0     3.0              10.0  NaN  \n",
      "3      2.0     3.0              11.0  NaN  \n",
      "4      3.0     3.0               5.0  3.0  \n"
     ]
    }
   ],
   "source": [
    "#renaming columns\n",
    "df_comments = df_comments.rename(columns = {\"GIPFELID\":\"summit_id\",\n",
    "                                        \"WEGID\":\"route_id\",\n",
    "                                        \"SEKTORID\":\"sector_id\",\n",
    "                                        \"KOMMENTID\":\"comment_id\",\n",
    "                                        \"SCHWIERIGKEIT\":\"grade_maybelater\",\n",
    "                                        \"QUALITAET\":\"quality\",\n",
    "                                        \"SICHERUNG\":\"safety\",\n",
    "                                        \"NAESSE\":\"wet\",\n",
    "                                        \"DATUM\":\"date_comment\",\n",
    "                                        \"KOMMENTAR\":\"comment_de\"\n",
    "                                       })\n",
    "print(df_comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f84bf21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                              | 69/4476 [00:12<13:06,  5.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",

     ]
    }
   ],
   "source": [
    "#initialize translator object\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "\n",
    "#function to translate comments into english\n",
    "def translate_comments(df_comments):\n",
    "    en_com = []\n",
    "    for comment in tqdm(df_comments[\"comment_de\"].to_list()): #iterate through german comments\n",
    "        en_com.append(translator.translate(comment).text) #translate and append to list \"en_com\"\n",
    "    return en_com\n",
    "\n",
    "#translating the comments and create new column\n",
    "df_comments[\"comment_en\"] = translate_comments(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ec01155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some columns\n",
    "del df_routes[\"routes_per_summit\"]\n",
    "df_summit = df_summit.drop(columns = [\"count_routes\", \"summit_counts\"])\n",
    "\n",
    "#export \n",
    "writer = pd.ExcelWriter(\"climbing_data_25_01.xlsx\", engine =\"xlsxwriter\")\n",
    "df_scales.to_excel(writer, sheet_name = \"scales\", index=False)\n",
    "df_routes.to_excel(writer, sheet_name = \"routes\", index=False)\n",
    "df_summit.to_excel(writer, sheet_name = \"summits\", index=False)\n",
    "df_sub_region.to_excel(writer, sheet_name = \"sub_regions\", index=False)\n",
    "df_comments.to_excel(writer, sheet_name = \"comments\", index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
